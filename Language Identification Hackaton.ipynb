{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Language Identification Hackaton**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "South Africa is a multicultural society that is characterised by its rich linguistic diversity with 11 official langauges. We are building a machine learning algorithm that could determine the natural language that a piece of text is written in (using texts in South Africa languages for the model building)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing of Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Packages for visualizations\n",
    "import seaborn as sns\n",
    "import matplotlib.style as style\n",
    "\n",
    "# Packages for preprocessing\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Packages for training models\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "\n",
    "# Model Evaluation Packages\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Style\n",
    "sns.set(font_scale=1.5)\n",
    "style.use('seaborn-pastel')\n",
    "style.use('seaborn-poster')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the dataset \n",
    "train = pd.read_csv('train_set.csv')\n",
    "test = pd.read_csv('test_set.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
      "1    i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
      "2    the province of kwazulu-natal department of tr...\n",
      "3    o netefatša gore o ba file dilo ka moka tše le...\n",
      "4    khomishini ya ndinganyiso ya mbeu yo ewa maana...\n",
      "5    dinyakišišo tše tša go dirwa gabedi ka ngwaga ...\n",
      "6    kgetse nngwe le nngwe e e sa faposiwang mo tsh...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train['text'].head(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Ke feela dilense tše hlakilego, tša pono e tee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>&lt;fn&gt;(762010101403 AM) 1495 Final Gems Birthing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4      5                      Winste op buitelandse valuta.\n",
       "5      6  Ke feela dilense tše hlakilego, tša pono e tee...\n",
       "6      7  <fn>(762010101403 AM) 1495 Final Gems Birthing..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lang_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>nbl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index lang_id\n",
       "0      1     tsn\n",
       "1      2     nbl"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 General Overview of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tso    3000\n",
       "sot    3000\n",
       "eng    3000\n",
       "nbl    3000\n",
       "ven    3000\n",
       "nso    3000\n",
       "tsn    3000\n",
       "xho    3000\n",
       "afr    3000\n",
       "zul    3000\n",
       "ssw    3000\n",
       "Name: lang_id, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.lang_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA\n",
      "=============\n",
      "\n",
      "Shape of the dataset: (33000, 2)\n",
      "\n",
      "Total Number of unique tweets: 29948\n",
      "\n",
      "Total Number of missing values:\n",
      "lang_id    0\n",
      "text       0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "TEST DATA\n",
      "=========\n",
      "\n",
      "Shape of the dataset: (5682, 2)\n",
      "\n",
      "Total Number of unique tweets: 5459\n",
      "\n",
      "Total Number of missing values:\n",
      "index    0\n",
      "text     0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Taking general overview at both datasets\n",
    "print('TRAINING DATA')\n",
    "print('============='+('\\n'))\n",
    "print('Shape of the dataset: {}\\n'.format(train.shape))\n",
    "print('Total Number of unique tweets: {}\\n'.format(len(set(train['text']))))\n",
    "print('Total Number of missing values:\\n{}\\n\\n'.format(train.isnull().sum()))\n",
    "print('TEST DATA')\n",
    "print('========='+('\\n'))\n",
    "print('Shape of the dataset: {}\\n'.format(test.shape))\n",
    "print('Total Number of unique tweets: {}\\n'.format(len(set(test['text']))))\n",
    "print('Total Number of missing values:\\n{}\\n' .format(test.isnull().sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    This function uses regular expressions to remove html characters,\n",
    "    punctuation, numbers and any extra white space from each text\n",
    "    and then converts them to lowercase.\n",
    "\n",
    "    Input:\n",
    "    text: original text\n",
    "          datatype: string\n",
    "\n",
    "    Output:\n",
    "    texts: modified text\n",
    "           datatype: string\n",
    "    \"\"\"\n",
    "    # replace the html characters with \" \"\n",
    "    text=re.sub('<.*?>', ' ', text)\n",
    "#     Removal of numbers\n",
    "#    text = re.sub(r'\\d+', ' ', text)\n",
    "    # will replace newline with space\n",
    "    text = re.sub(\"\\n\",\" \",text)\n",
    "    # will convert to lower case\n",
    "    text = text.lower()\n",
    "    # will split and join the words\n",
    "    text=' '.join(text.split())\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application of the function to clean the tweets\n",
    "train['text'] = train['text'].apply(clean_text)\n",
    "test['text'] = test['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '.txt' with 'text file'\n",
    "train[\"text\"] = train[\"text\"].str.replace(\".txt\", \" text file\")\n",
    "test[\"text\"] = test[\"text\"].str.replace(\".txt\", \" text file\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Splitting out X (indepedent) and Y (target/dependent) variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train['text']\n",
    "y = train['lang_id']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Splitting of Training and Validation Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Setting up Classifiers for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Note: Some classifiers were commented out because\n",
    "they run for a very long time, \n",
    "\"\"\"\n",
    "classifiers = [LinearSVC(random_state=42),\n",
    "               # SVC(),\n",
    "               # tree.DecisionTreeClassifier(),\n",
    "               # RandomForestClassifier(n_estimators=100, max_depth=2,\n",
    "               #                      random_state=0, class_weight=\"balanced\"),\n",
    "               # MLPClassifier(alpha=1e-5,\n",
    "               #              hidden_layer_sizes=(5, 2),\n",
    "               #              random_state=42),\n",
    "               LogisticRegression(random_state=42,\n",
    "                                  multi_class='ovr',\n",
    "                                  n_jobs=1,\n",
    "                                  C=1e5,\n",
    "                                  max_iter=4000),\n",
    "               KNeighborsClassifier(n_neighbors=5),\n",
    "               MultinomialNB(),\n",
    "               ComplementNB(),\n",
    "               SGDClassifier(loss='hinge',\n",
    "                             penalty='l2',\n",
    "                             alpha=1e-3,\n",
    "                             random_state=42,\n",
    "                             max_iter=5,\n",
    "                             tol=None)\n",
    "               # GradientBoostingClassifier()\n",
    "               # xgb.XGBClassifier(learning_rate=0.1,\n",
    "               #                  n_estimators=1000,\n",
    "               #                  max_depth=5,\n",
    "               #                  min_child_weight=1,\n",
    "               #                  gamma=0,\n",
    "               #                  subsample=0.8,\n",
    "               #                  colsample_bytree=0.8,\n",
    "               #                  nthread=4,\n",
    "               #                  seed=27)\n",
    "               ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating Function for Model Building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_building(classifiers, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    This function takes in a list of classifiers\n",
    "    and both the train and validation sets\n",
    "    and return a summary of F1-score and\n",
    "    processing time as a dataframe\n",
    "\n",
    "    Input:\n",
    "    classifiers: a list of classifiers to train\n",
    "                 datatype: list\n",
    "    X_train: independent variable for training\n",
    "             datatype: series\n",
    "    y_train: dependent variable for training\n",
    "             datatype: series\n",
    "    X_val: independent variable for validation\n",
    "           datatype: series\n",
    "    y_val: dependent variable for validation\n",
    "           datatype: series\n",
    "\n",
    "    Output:\n",
    "    model_summary: F1 Score for all the classifiers\n",
    "                   datatype: dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    models_summary = {}\n",
    "\n",
    "    # Pipeline to balance the classses and then to build the model\n",
    "    for clf in classifiers:\n",
    "        clf_text = Pipeline([('tfidf', TfidfVectorizer(min_df=1,\n",
    "                                                       max_df=0.9,\n",
    "                                                       ngram_range=(1, 2))),\n",
    "                             ('clf', clf)])\n",
    "\n",
    "        # Logging the Execution Time for each model\n",
    "        start_time = time.time()\n",
    "        clf_text.fit(X_train, y_train)\n",
    "        predictions = clf_text.predict(X_val)\n",
    "        run_time = time.time()-start_time\n",
    "\n",
    "        # Output for each model\n",
    "        models_summary[clf.__class__.__name__] = {\n",
    "            'F1-Macro': metrics.f1_score(y_val,\n",
    "                                         predictions,\n",
    "                                         average='macro'),\n",
    "            'F1-Accuracy': metrics.f1_score(y_val, predictions,\n",
    "                                            average='micro'),\n",
    "            'F1-Weighted': metrics.f1_score(y_val,\n",
    "                                            predictions,\n",
    "                                            average='weighted'),\n",
    "            'Execution Time': run_time}\n",
    "\n",
    "    return pd.DataFrame.from_dict(models_summary, orient='index')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 Execution of the Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1-Macro</th>\n",
       "      <th>F1-Accuracy</th>\n",
       "      <th>F1-Weighted</th>\n",
       "      <th>Execution Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.998806</td>\n",
       "      <td>0.998788</td>\n",
       "      <td>0.998788</td>\n",
       "      <td>12.468319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ComplementNB</th>\n",
       "      <td>0.998208</td>\n",
       "      <td>0.998182</td>\n",
       "      <td>0.998182</td>\n",
       "      <td>9.540652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.997596</td>\n",
       "      <td>0.997576</td>\n",
       "      <td>0.997576</td>\n",
       "      <td>16.454023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.997287</td>\n",
       "      <td>0.997273</td>\n",
       "      <td>0.997271</td>\n",
       "      <td>301.108936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.985795</td>\n",
       "      <td>0.985758</td>\n",
       "      <td>0.985705</td>\n",
       "      <td>12.971319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.965202</td>\n",
       "      <td>0.965152</td>\n",
       "      <td>0.964845</td>\n",
       "      <td>18.384171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      F1-Macro  F1-Accuracy  F1-Weighted  Execution Time\n",
       "MultinomialNB         0.998806     0.998788     0.998788       12.468319\n",
       "ComplementNB          0.998208     0.998182     0.998182        9.540652\n",
       "LinearSVC             0.997596     0.997576     0.997576       16.454023\n",
       "LogisticRegression    0.997287     0.997273     0.997271      301.108936\n",
       "SGDClassifier         0.985795     0.985758     0.985705       12.971319\n",
       "KNeighborsClassifier  0.965202     0.965152     0.964845       18.384171"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers_df = models_building(classifiers, X_train, y_train, X_val, y_val)\n",
    "ordered_df = classifiers_df.sort_values('F1-Macro', ascending=False)\n",
    "ordered_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 Comparing Classification Methods\n",
    "\n",
    "The most performing is the Multinomial Naive Bayes with F1-Macro of 99.9% and accuracy of 99.9% while closely followed by Complement Naive Bayes, Logistic Regression, Linear Support Vector Classifier, Support Vector Machine etc.\n",
    "\n",
    "We will proceed with the first two algorithms (to see which will come out better) by applying hyperparameter tunining, as they are the most performing models and considering their execution time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Hyperparameter Tuning on Most Performing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refining the train-test split for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.02)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00        60\n",
      "         eng       0.98      1.00      0.99        47\n",
      "         nbl       1.00      1.00      1.00        64\n",
      "         nso       1.00      1.00      1.00        60\n",
      "         sot       1.00      1.00      1.00        66\n",
      "         ssw       1.00      1.00      1.00        56\n",
      "         tsn       1.00      1.00      1.00        57\n",
      "         tso       1.00      1.00      1.00        55\n",
      "         ven       1.00      1.00      1.00        72\n",
      "         xho       1.00      0.98      0.99        57\n",
      "         zul       1.00      1.00      1.00        66\n",
      "\n",
      "    accuracy                           1.00       660\n",
      "   macro avg       1.00      1.00      1.00       660\n",
      "weighted avg       1.00      1.00      1.00       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a pipeline for the gridsearch\n",
    "param_grid = {'alpha': [0.1, 1, 5, 10]}  # setting parameter grid\n",
    "\n",
    "tuned_mnb = Pipeline([('tfidf', TfidfVectorizer(min_df=1,\n",
    "                                                max_df=0.5,\n",
    "                                                ngram_range=(1, 2))),\n",
    "                      ('mnb', GridSearchCV(MultinomialNB(),\n",
    "                                           param_grid=param_grid,\n",
    "                                           cv=10,\n",
    "                                           n_jobs=-1,\n",
    "                                           scoring='f1_weighted'))\n",
    "                      ])\n",
    "\n",
    "tuned_mnb.fit(X_train, y_train)  # Fitting the model\n",
    "\n",
    "y_pred_mnb = tuned_mnb.predict(X_val)  # predicting the fit on validation set\n",
    "\n",
    "print(classification_report(y_val, y_pred_mnb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Creating File for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(test['index'])\n",
    "submission_df['lang_id'] = tuned_mnb.predict(test['text'])\n",
    "submission_df.to_csv('submission_tuned_multinomial_NB.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several algorithms were tried and Multinomial Naive Bayes classifier was the most performing. It performed very well on the training and validation datasets with an accuracy score of over 99% and F1 Macro score of over 99%. After testing the fitted model on the held-out/unseen dataset, it was able to predict the classes of languages with an F1 Score of about 97%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Hyperparameters and Model Validation (An overview of classification model hyperparameters, hyperparameter tuning, and model validation) - Explore Data Science Academy\n",
    "2. https://scikit-learn.org/stable/modules/grid_search.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
