{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Packages for visualizations\n",
    "import seaborn as sns\n",
    "import matplotlib.style as style\n",
    "\n",
    "# Packages for preprocessing\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Packages for training models\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Model Evaluation Packages\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Style\n",
    "sns.set(font_scale=1.5)\n",
    "style.use('seaborn-pastel')\n",
    "style.use('seaborn-poster')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the dataset \n",
    "train = pd.read_csv('train_set.csv')\n",
    "test = pd.read_csv('test_set.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
      "1    i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
      "2    the province of kwazulu-natal department of tr...\n",
      "3    o netefatša gore o ba file dilo ka moka tše le...\n",
      "4    khomishini ya ndinganyiso ya mbeu yo ewa maana...\n",
      "5    dinyakišišo tše tša go dirwa gabedi ka ngwaga ...\n",
      "6    kgetse nngwe le nngwe e e sa faposiwang mo tsh...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train['text'].head(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>mmasepala fa maemo a a kgethegileng a letlelel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>tshivhumbeo tshi fana na ngano dza vhathu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>winste op buitelandse valuta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>ke feela dilense te hlakilego ta pono e tee go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>am final gems birthing optionszulutxt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      1  mmasepala fa maemo a a kgethegileng a letlelel...\n",
       "1      2  uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2      3          tshivhumbeo tshi fana na ngano dza vhathu\n",
       "3      4  kube inja nelikati betingevakala kutsi titsini...\n",
       "4      5                       winste op buitelandse valuta\n",
       "5      6  ke feela dilense te hlakilego ta pono e tee go...\n",
       "6      7              am final gems birthing optionszulutxt"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lang_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>nbl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index lang_id\n",
       "0      1     tsn\n",
       "1      2     nbl"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Overview of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nbl    3000\n",
       "ven    3000\n",
       "sot    3000\n",
       "eng    3000\n",
       "afr    3000\n",
       "tso    3000\n",
       "tsn    3000\n",
       "ssw    3000\n",
       "zul    3000\n",
       "xho    3000\n",
       "nso    3000\n",
       "Name: lang_id, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.lang_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA\n",
      "=============\n",
      "\n",
      "Shape of the dataset: (33000, 2)\n",
      "\n",
      "Total Number of unique tweets: 29948\n",
      "\n",
      "Total Number of missing values:\n",
      "lang_id    0\n",
      "text       0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "TEST DATA\n",
      "=========\n",
      "\n",
      "Shape of the dataset: (5682, 2)\n",
      "\n",
      "Total Number of unique tweets: 5459\n",
      "\n",
      "Total Number of missing values:\n",
      "index    0\n",
      "text     0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Taking general overview at both datasets\n",
    "print('TRAINING DATA')\n",
    "print('============='+('\\n'))\n",
    "print('Shape of the dataset: {}\\n'.format(train.shape))\n",
    "print('Total Number of unique tweets: {}\\n'.format(len(set(train['text']))))\n",
    "print('Total Number of missing values:\\n{}\\n\\n'.format(train.isnull().sum()))\n",
    "print('TEST DATA')\n",
    "print('========='+('\\n'))\n",
    "print('Shape of the dataset: {}\\n'.format(test.shape))\n",
    "print('Total Number of unique tweets: {}\\n'.format(len(set(test['text']))))\n",
    "print('Total Number of missing values:\\n{}\\n' .format(test.isnull().sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    This function uses regular expressions to remove html characters,\n",
    "    punctuation, numbers and any extra white space from each text\n",
    "    and then converts them to lowercase.\n",
    "\n",
    "    Input:\n",
    "    tweets: original text\n",
    "            datatype: string\n",
    "\n",
    "    Output:\n",
    "    tweets: modified text\n",
    "            datatype: string\n",
    "    \"\"\"\n",
    "    #will replace the html characters with \" \"\n",
    "    text=re.sub('<.*?>', ' ', text)  \n",
    "    #To remove the punctuations\n",
    "#    text = text.translate(str.maketrans(' ',' ',string.punctuation))\n",
    "#    pattern = r'[^a-zA-z0-9\\s]' if not False else r'[^a-zA-z\\s]'\n",
    "#    text = re.sub(pattern, '', text)\n",
    "    # Removal of numbers\n",
    "#    text = re.sub(r'\\d+', ' ', text)\n",
    "    #will replace newline with space\n",
    "    text = re.sub(\"\\n\",\" \",text)\n",
    "    #will convert to lower case\n",
    "    text = text.lower()\n",
    "    # will split and join the words\n",
    "    text=' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application of the function to clean the tweets\n",
    "train['text'] = train['text'].apply(clean_text)\n",
    "test['text'] = test['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train['text']\n",
    "y = train['lang_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"text\"] = train[\"text\"].str.replace(\".txt\", \" text file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"text\"] = test[\"text\"].str.replace(\".txt\", \" text file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSVC=Pipeline([('LSVC_tfidf',\n",
    "                TfidfVectorizer(min_df=2, strip_accents='ascii',\n",
    "                                smooth_idf=False,\n",
    "                                ngram_range=(1,2)\n",
    "                                )\n",
    "                ),\n",
    "                ('LSVC',\n",
    "                 LinearSVC(random_state=42))\n",
    "               ])\n",
    "\n",
    "LSVC.fit(X_train,y_train)\n",
    "\n",
    "ypred_lsvc=LSVC.predict(X_val)\n",
    "\n",
    "print(classification_report(y_val,ypred_lsvc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df=pd.DataFrame(df_test['index'])\n",
    "sub_df['lang_id']=LSVC.predict(df_test['text'])\n",
    "sub_df.to_csv('Linear_SVC.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.02)  #### .15 is the best .20 is better than .25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'alpha':[0.01, 0.1, 1, 5, 10, 20, 50]}\n",
    "tuned_nb = Pipeline([('tfidf', TfidfVectorizer(min_df=1, \n",
    "                                             max_df=0.5, \n",
    "                                             ngram_range=(1, 2))),\n",
    "                     ('nb', GridSearchCV(MultinomialNB(),\n",
    "                                         param_grid=param_grid,\n",
    "                                         cv=10,\n",
    "                                         n_jobs=-1,\n",
    "                                         scoring='f1_weighted'))\n",
    "                     ])\n",
    "\n",
    "tuned_nb.fit(X_train, y_train)\n",
    "\n",
    "tuned_nb2 = tuned_nb.predict(X_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df=pd.DataFrame(test['index'])\n",
    "submission_df['lang_id']=tuned_nb.predict(test['text'])\n",
    "submission_df.to_csv('submission_multinomial_nb.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
